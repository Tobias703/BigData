{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install plotly\n",
    "%pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup and Data Structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas settings\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 0)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "# Defining variables and functions\n",
    "sensors = [\"dig1\", \"ana1\", \"noise\"]\n",
    "def visualize_dataframe(df, sample_size=None):\n",
    "    # Downsample the DataFrame if sample_size is provided\n",
    "    if sample_size:\n",
    "        downsampled_df = df.sample(n=sample_size).sort_values(by=['Time'])\n",
    "    else:\n",
    "        downsampled_df = df\n",
    "    \n",
    "    # Melt the DataFrame\n",
    "    melted_df = downsampled_df.melt(id_vars=['Time'], value_vars=['ana1', 'dig1', 'noise'], var_name='Sensor', value_name='Value')\n",
    "    \n",
    "    # Create a Plotly figure\n",
    "    fig = px.line(melted_df, x='Time', y='Value', color='Sensor', title='Sensor Data Over Time')\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title='Value',\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    # Show the figure\n",
    "    fig.show()\n",
    "\n",
    "# Load the data from the CSV file\n",
    "df = pd.read_csv('_initial_dataset.csv', comment='#', low_memory=False)\n",
    "\n",
    "# Drop the unnecessary columns\n",
    "df = df.drop(columns=['Unnamed: 0', 'result', '_start', '_stop', '_field', 'table', 'host', 'topic'])\n",
    "df = df.rename(columns={'_time': 'Time', '_value': 'Value', '_measurement': 'Sensor', 'serial': 'Index', 'unit': 'Unit'})\n",
    "\n",
    "# Reorder the columns\n",
    "columns_order = ['Index', 'Sensor', 'Value', 'Unit', 'Time']\n",
    "df = df[columns_order]\n",
    "\n",
    "# Convert the data types for easier reading\n",
    "# df['Index'] = df['Index'].astype(str)\n",
    "# df['Index'] = df['Index'].str.zfill(6)\n",
    "# df['Time'] = pd.to_datetime(df['Time']).dt.strftime('%d.%m.%Y %H:%M:%S')\n",
    "\n",
    "# Sort the data by the index and the sensor\n",
    "sensor_order = {'dig1': 1, 'ana1': 2, 'noise': 3}\n",
    "df['SensorOrder'] = df['Sensor'].map(sensor_order)\n",
    "df = df.sort_values(by=['Index', 'SensorOrder']).drop(columns=['SensorOrder'])\n",
    "\n",
    "# Set the Index column as the actual table-index\n",
    "df.set_index('Index', inplace=True)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Search the DataFrame for mismatches in Sensordata/Availability for the same indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: move this logic to datacleaning and apply it to the compressed dataframe\n",
    "expected_sensors = {'dig1', 'ana1', 'noise'}\n",
    "# Identify rows with missing sensor values\n",
    "missing_sensors = []\n",
    "for idx, group in df.groupby(df.index):\n",
    "    present_sensors = set(group['Sensor'])\n",
    "    missing = expected_sensors - present_sensors\n",
    "    for sensor in missing:\n",
    "        missing_sensors.append({'Index': idx, 'Missing Sensor': sensor})\n",
    "\n",
    "# Create a DataFrame to display missing sensors\n",
    "missing_sensors_df = pd.DataFrame(missing_sensors)\n",
    "\n",
    "# Print the indices with missing sensor values\n",
    "print(\"Indices with missing sensor values:\")\n",
    "print(missing_sensors_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot the DataFrame to Save 2/3 of the Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the DataFrame\n",
    "time_df = df[df['Sensor'] == 'dig1'][['Time']].reset_index()\n",
    "pivot_df = df.pivot_table(index=df.index, columns='Sensor', values='Value').reset_index()\n",
    "pivot_df = pivot_df.merge(time_df, on='Index', how='left')\n",
    "pivot_df.set_index('Index', inplace=True)\n",
    "\n",
    "# Display the pivoted DataFrame\n",
    "print(pivot_df.head())\n",
    "\n",
    "pivot_df.to_csv('1datasetCompressed.csv')\n",
    "\n",
    "small_df = pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a List with Pairs of Datapoints with from/to values of Missing IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indexes = pd.Series(range(small_df.index.min(), small_df.index.max() + 1))\n",
    "missing_indexes = all_indexes[~all_indexes.isin(small_df.index)]\n",
    "\n",
    "# Find ranges of missing indexes\n",
    "missing_ranges = []\n",
    "for k, g in groupby(enumerate(missing_indexes), lambda x: x[0] - x[1]):\n",
    "    group = list(map(itemgetter(1), g))\n",
    "    missing_ranges.append((group[0], group[-1]))\n",
    "\n",
    "# Create a DataFrame with the required columns\n",
    "missing_data = []\n",
    "for start, end in missing_ranges:\n",
    "    first_missing_date = small_df.loc[start - 1, 'Time'] if start - 1 in small_df.index else None\n",
    "    last_missing_date = small_df.loc[end + 1, 'Time'] if end + 1 in small_df.index else None\n",
    "    missing_data.append([start, end, first_missing_date, last_missing_date])\n",
    "\n",
    "missing_df = pd.DataFrame(missing_data, columns=['First Missing Index', 'Last Missing Index', 'First Missing Time', 'Last Missing Time'])\n",
    "\n",
    "print(missing_df.head())\n",
    "\n",
    "# Visualize the DataFrame\n",
    "first_time = small_df['Time'].iloc[0]\n",
    "last_time = small_df['Time'].iloc[-1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
